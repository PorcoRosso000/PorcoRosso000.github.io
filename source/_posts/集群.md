---
title: 集群
typora-root-url: 集群
abbrlink: e93d36ed
date: 2022-11-26 16:19:37
keywords: '集群'
tags: 集群
categories: 集群
photos:
description: 集群
---

集群

<!--more-->

------



# 集群

#### redis集群

##### redis集群模式

 1、主从模式（手动切换主从）

 主从复制模式原理：  

- 从数据库连接主数据库，发送的是SYNC的请求
- 主数据库接收到SYNC的请求之后，开始执行bgsave命令，并且生成RDB文件
- 主数据库 	执行完bgsave命令，向从数据库去发送快照文件，在此期间主数据可以继续执行写操作
- 从数据接收到文件之后，摒弃旧的替换新的文件
- 主数据库向从数据库发送缓存中的写操作
- 从数据库对快照进行一个载入操作，同时接收主数据库发送过来的缓存写操作
- 出现重新连接的操作的时候，会有一个增量复制操作
- 主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步

 主从模式的优点：支持主从复制，可以读写分离  

 最主要的还是为master分担的压力

 主从模式的缺点：宕机的时候，如果主的数据没有同步到从数据库中去，那么就会造成数据的丢失  

 需要手动去切换主服务，费时费力 ，还可能造成一段时间不可以使用的情况  

 redis支持扩容是很难的

 2、哨兵模式（自动选举主）

主要功能

监控（Monitoring）：Sentinel会不断的检查你的主节点和从节点是否正常工作。

通知（Notification）：被监控的Redis实例如果出现问题，Sentinel可以通过API（pub）通知系统管理员或者其他程序。

自动故障转移（Automatic failover）：如果一个 master 离线，Sentinel 会开始进行故障转移，master 下的一个slave 会被选为新的 master，其他的 slave 会开始复制新的 master。应用可以通过 Redis 服务的通知机制更新新的master 地址。

配置提供（Configuration provider）：客户端可以把 Sentinel 作为权威的配置发布者来获得最新的 master 地址。如果发生了故障转移，Sentinel 集群会通知客户端新的 master 地址，并刷新 Redis 的配置。

 哨兵模式是一种特殊的模式，哨兵是一个独立的进程，可以独立运行。

 哨兵模式的作用：

- 通过发送命令，可以监控运行状态，包括主从服务器
- 当主服务器宕机的时候，会自动去切换新的主服务器，通过发布订阅模式去通知其他的从服务器进行配置的更改，切换主机；可以采用 	多哨兵模式去进行监管主服务器

 故障切换的过程：

 如果主服务器宕机了，监管它的哨兵监测不到消息，在这个时候不会进行failover，这种现象为主管下线。要让其他的哨兵一同去发送ping命令，如果全部都没有检测到，那么这个时候哨兵会重新发布推举，整个服务进行failover操作，此时为客观下线，推选出新的主服务器的时候，采用发布订阅模式去通知其他从服务器，更改配置，进行主机的切换。

 哨兵模式的工作流程 ：

- 每个以每一秒一次的去监管主服务器去给从服务器以及其他的哨兵去发送ping命令
- 如果最后一次有效回复的ping命令超过了down-after-milliseconds的值，那么实例就会认为此时主机发生了主观下线。
- 如果主服务器被认为 	是主观下线，那么其他的哨兵都会以每秒一次的频率去确认这个主服务器是否真的宕机
- 如果全部哨兵监测到的是主观下线，那么就是客观下线
- 一般情况下，每个哨兵会以10秒的一次探测频率去监测主服务器、从服务器。
- 如主服务器被认为是客观下线，那么哨兵在推选的新的主服务器的时候会以每秒一次的频率去发送info命令
- 如果有哨兵不同意主服务器下线，那么是可以从客观下线状态中移除的。如果说主服务器突然活了，发送命令了，那么也是可以从主管下线中移除的。

 哨兵模式的优点：

 哨兵模式是基于主从模式的，所以主从有的哨兵都有。

 主从需要手动去切换主服务器，而哨兵不需要

 哨兵模式的缺点：

 redis较难支持在线扩容

 3、集群

 redis的哨兵模式已经实现了高可用，读写分离，但是哨兵模式下每台服务器都存储相同的数据，浪费内存，所以在3.0以后加入了集群模式，实现了分布式

 存储，就是每台redis节点上存储不同的内容

##### redis cluster 特点

- 所有的redis结点都是彼此互联的
- 客户端连接集群的时候不需要关心分片的计算逻辑，客户端直接将key交给redis中的结点，最终由内部判断key值的正确存储位置
- redis集群是吧所有的主节点都交给对应的卡槽去处理【0-16383】，由主节点去维护一批数据。数据主要是被哪个结点维护是判断对应key的取模运算，如果要迁移某个key值，必须将对应的slot（槽）一并迁移

#### nacos集群

##### nacos集群创建方式

 1.安装3个以上Nacos
 我们可以复制之前已经解压好的nacos文件夹，分别命名为nacos2、nacos3、nacos4  

 2.在所有nacos目录的conf目录下，有文件 cluster.conf.example ，将其命名为 cluster.conf ，并将每行配置成
 ip:port。（请配置3个或3个以上节点）  

 3.由于是单机演示，需要更改nacos/的conf目录下application.properties中server.port，防止端口冲突。
 如果服务器有多个ip也要指定具体的ip地址，如：nacos.inetutils.ip-address=127.0.0.1  

 4.进入nacos的conf目录，编辑application.properties文件，增加数据库配置  

 5.集群模式启动
 分别执行nacos目录的bin目录下的startup：

```
startup.cmd -m cluster
```

 6.启动后登录nacos三个节点都启动

##### Nacos 集群中 Leader 节点是如何产生的？

 Nacos 集群采用 Raft 算法实现。它是一种比较简单的选举算法，用于选举出 Nacos 集群中最重要的 Leader（领导）节点。

 在 Nacos 集群中，每个节点都拥有以下三种角色中的一种。

- Leader：领导者，集群中最重要的角色，用于向其他节点下达指令。
- Candidate：参选者，参与竞选 	Leader 	的节点。
- Follower：跟随者，用于接收来自 	Leader 	或者 	Candidate 	的请求并进行处理。

 在集群中选举出 Leader 是最重要的工作，产生选举的时机有三个：

- 在 	Nacos 	节点启动后，还没有产生Leader时选举；
- 集群成员总量变更时重新选举；
- 当 	Leader 	停止服务后重新选举；

##### Nacos 节点间的数据同步过程

 Nacos 节点间的数据同步过程

 在 Raft 算法中，只有 Leader 才拥有数据处理与信息分发的权利。因此当微服务启动时，假如注册中心指定为 Follower 节点，则步骤如下：

 第一步，Follower 会自动将注册心跳包转给 Leader 节点；

 第二步，Leader 节点完成实质的注册登记工作；

 第三步，完成注册后向其他 Follower 节点发起“同步注册日志”的指令；

 第四步，所有可用的 Follower 在收到指令后进行“ack应答”，通知 Leader 消息已收到；

 第五步，当 Leader 接收过半数 Follower 节点的 “ack 应答”后，返回给微服务“注册成功”的响应信息。

 此外，对于其他无效的 Follower 节点，Leader 仍会不断重新发送，直到所有 Follower 的状态与 Leader 保持同步。

 nacos配置中心

 nacos既有注册中心也有配置中心

 注册中心对使用nacos的微服务进行了统一管理

 配置中心对项目中的配置做了统一的配置管理 方便后期维护

##### nacos集群搭建原因

 保障系统的高可用性有两个大道至简的方向。

- 避免单点故障：在做系统架构的时候，你应该假设任何服务器都有可能挂掉。如果某项任务依赖单一服务资源，那么这就会成为一个“单点”，一旦这个服务资源挂掉就表示整个功能变为不可用。所以你要尽可能消灭一切“单点”；
- 故障机器状态恢复：尽快将故障机器返回到故障前的状态。对于像 	Nacos 	这类中心化注册中心来说，因故障而下线的机器在重新上线后，应该有能力从某个地方获取故障发生前的服务注册列表。

#### Rabbitmq高可用搭建

##### 为什么使用集群？

内建集群作为RabbitMQ最优秀的功能之一，它的作用有两个：

允许消费者和生产者在Rabbit节点崩溃的情况下继续运行；

通过增加节点来扩展Rabbit处理更多的消息，承载更多的业务量；

##### 集群的特点

RabbitMQ的集群是由多个节点组成的，但我们发现不是每个节点都有所有队列的完全拷贝。

RabbitMQ节点不完全拷贝特性

##### 为什么默认情况下RabbitMQ不将所有队列内容和状态复制到所有节点？

有两个原因：

存储空间——如果每个节点都拥有所有队列的完全拷贝，这样新增节点不但没有新增存储空间，反而增加了更多的冗余数据。

性能——如果消息的发布需安全拷贝到每一个集群节点，那么新增节点对网络和磁盘负载都会有增加，这样违背了建立集群的初衷，新增节点并没有提升处理消息的能力，最多是保持和单节点相同的性能甚至是更糟。

所以其他非所有者节点只知道队列的元数据，和指向该队列节点的指针。

##### 集群异常处理

根据节点不无安全拷贝的特性，当集群节点崩溃时，该节点队列和关联的绑定就都丢失了，附加在该队列的消费者丢失了其订阅的信息，那么怎么处理这个问题呢？

这个问题要分为两种情况：

消息已经进行了持久化，那么当节点恢复，消息也恢复了；

消息未持久化，可以使用下文要介绍的双活冗余队列，镜像队列保证消息的可靠性；

##### 集群节点类型

节点的存储类型分为两种：

磁盘节点

内存节点

磁盘节点就是配置信息和元信息存储在磁盘上，内次节点把这些信息存储在内存中，当然内次节点的性能是大大超越磁盘节点的。

单节点系统必须是磁盘节点，否则每次你重启RabbitMQ之后所有的系统配置信息都会丢失。

RabbitMQ要求集群中至少有一个磁盘节点，当节点加入和离开集群时，必须通知磁盘节点。

特殊异常：集群中唯一的磁盘节点崩溃了

如果集群中的唯一一个磁盘节点，结果这个磁盘节点还崩溃了，那会发生什么情况？

如果唯一磁盘的磁盘节点崩溃了，不能进行如下操作：

不能创建队列

不能创建交换器

不能创建绑定

不能添加用户

不能更改权限

不能添加和删除集群几点

总结：如果唯一磁盘的磁盘节点崩溃，集群是可以保持运行的，但你不能更改任何东西。

解决方案：在集群中设置两个磁盘节点，只要一个可以，你就能正常操作。

##### 集群搭建方法

步骤一：安装多个RabbitMQ

步骤二：加入RabbitMQ节点到集群

 	设置三个节点

#### 服务集群

实例名称一样未来就是集群

实例名称替换端口号使用 可以实现在任意机器上调用