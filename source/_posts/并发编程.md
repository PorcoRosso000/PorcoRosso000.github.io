---
title: 并发编程
typora-root-url: 并发编程
abbrlink: ace12490
date: 2022-11-26 17:06:32
tags:
permalink:
---



## 并发量

//---------------------------------------------

Tomcat 并发量：500qps  

Mysql：3000qps  

Redis：5万-8万

Nginx：5万-10万

 网站并发量：3000,5000,8000, 在线用户，电商x50 ，其它互联网项目x80 ， 注册用户，在在线用户的基础上x50.(3000的并发:服务器一台tomcat支持500 所以要六台以上可以加两台 说8台)

 Tomcat (web应用服务器)

 nginx /apache(web服务),为文件服务器nginx性能是tomcat的10倍以上

内存标记 :消耗tomcat内存 可以支持的并发量也比较低   所以使用redis redis存储数据存储在本地  并且redis的并发量会高很多

电商项目开发时间:一年以上开发  迭代一直在持续

7个人开发    

几千的并发  并发 乘以50 就是在线人数  再乘以50  就是总注册人数

3000的并发服务器设置的刀片机（或者我们搭建的集群服务）是8台服务器左右抢购微服务

在添加订单之前通过redis集群方式加mq进行

## 高内聚，低耦合

 内聚就是指程序内的各个模块之间关系的紧密程度,



 耦合是指各个外部程序(子程序)之间关系的紧密程度.



 为什么要高内聚? 模块之间的关系越紧密,出错就越少!



 低耦合? 子程序间的关系越复杂,就会产生更多的意想不到的错误!会给以后的维护工作带来很多麻烦



 // 注释：“内紧而外松”

 内紧：程序内的模块之间要紧密相关，形成一个高效的功能单元；（旨在—创建高效的代码）

 外松：程序之间呢，要尽可能的不关联，各自实现各自的功能。（旨在—实现分工）



 秒杀订单多少   

 每天多少订单30000 3000并发量   



 秒杀订单的服务有几台   

 每天部署的有多少机器 平时秒杀并发量500-600  六台



 redis的锁过期时间  500ms  过期时间  看门狗锁过期续命原理  

 

## 限流

 

### Sentinel

Sentinel是阿里巴巴开发的一个流量控制、熔断和流量管理框架，它可以帮助我们在微服务架构中实现服务调用的容错、限流和流控。Sentinel的核心功能包括：

- 流控：限制请求数量，防止服务被过多的请求所击败。
- 熔断：当服务调用出现故障时，自动切换到备用方法，防止故障传播。
- 降级：在服务调用出现故障时，自动切换到备用方法，防止用户请求受影响。
- 系统负载保护：监控系统负载，当负载超过阈值时，自动进行流控或熔断。

Sentinel的核心思想是“限流”和“流控”，即在服务调用出现故障时，限制请求数量，防止服务被过多的请求所击败。同时，Sentinel还提供了一些规则配置，如流控规则、熔断规则等，可以根据具体情况进行调整。 

#### 实现原理:

**原理**是在访问web应用时，在web引用内部会有一个拦截器，这个拦截器会对请求的url进行拦截，并将拦截到的请求读取到sentinel控制台，从而对web应用设置相应的流控规则和需要的流控效果，之后基于这个流控规则和流控效果对流量进行限流操作。

 

Sentinel的**核心算法原理**是基于“限流”和“流控”的。当服务调用出现故障时，Sentinel会限制请求数量，防止服务被过多的请求所击败。同时，Sentinel还提供了一些规则配置，如流控规则、熔断规则等，可以根据具体情况进行调整。

 

**具体操作步骤如下：**

1.创建一个Sentinel流控规则，指定资源名称、流控条件、流控策略等。

2.在调用服务时，使用Sentinel流控规则进行控制。

3.当服务调用出现故障时，Sentinel会触发熔断器，切换到备用方法。

4.可以通过SentinelDashboard监控Sentinel流控规则的状态和统计信息。

#### 四种限流算法:

**对应三种流控效果:**

   **滑动窗口算法(默认):对应快速失败**

   **漏桶算法: 对应排队等待**

   **令牌桶算法: 对应预热** 

##### 固定窗口算法:

**固定窗口计数器算法**是限流算法中最简单也最容易实现的算法。它使用计数器在周期内累加访问次数，当达到设定的限流值时，触发限流策略。下一周期开始，清零重新计数。

举个例子，一个接口在1s内的负载限值为100，开始时设定一个计数器count=0，来一个请求count+1，1min内count<=100就能正常访问，count>100的请求就会被拒绝。

计数器算法的弊端在于只有最开始的100个请求能被访问，其余在限制时间内都不能访问。也就是突刺现象。这时就可以用滑动窗口算法解决这个问题。

突刺现象是指在一定时间内的一小段时间内就用完了所有资源，后大部分时间中无资源可用。

**优点**：分布式中实现难度低

**缺点：**不能平滑限流，存在临界问题，前一个周期的最后几秒和下一个周期的开始几秒时间段内访问量很大但没超过周期量计数量时，但短时间请求量依旧很高。

![img](1.jpg)


##### 滑动窗口算法(默认): 

**滑动窗口计数器算法**也是Sentinel的默认算法。滑动窗口算法是**将时间周期分为n个小周期，分别记录每个小周期内的访问次数 ，并且根据时间滑动删除过期的小周期**。

假设时间周期为1min，将1min再分割成2个小周期，统计每个小周期的访问数量，则可以看到，第一个时间周期内访问数量为75，第二个时间周期内访问数量为100，超过100的数量被限流掉了。

当滑动窗口格子划分得越多，那么滑动窗口的滚动就越平滑，限流的统计就越精确。可以很好的解决固定窗口的流动问题。

![img](2.jpg)

##### 漏桶算法: 

**漏桶算法是将访问请求放入漏桶中，当请求达到限流值，则进行丢弃（触发限流策略）**。无论有多少请求，请求的速率有多大，都按照固定的速率流出，对应到系统中就是按照固定的速率处理请求。超过漏桶容量的直接抛弃。

![img](3.jpg)

##### 令牌桶算法: 

令牌桶其实和漏桶的原理类似，令牌桶按固定的速率往桶里放入令牌，并且只要能从桶里取出令牌就能通过，令牌桶支持突发流量的快速处理。

![img](4.jpg)

###### 令牌桶和漏桶区别：

主要区别在于**“漏桶算法”能够强行限制数据的传输速率**，而**“令牌桶算法”在能够限制数据的平均传输速率外，还允许某种程度的突发传输**。在“令牌桶算法”中，只要令牌桶中存在令牌，那么就允许突发地传输数据直到达到用户配置的门限，因此它适合于具有突发特性的流量。

### 基于Redis的分布式令牌桶实现

Redis中有incr命令实现原子自增、如果每个调用appKey请求一次，我们对其自增1，如果一秒内超过500，就拒绝当前请求能够实现我们的需求。如何统计1秒内呢，我们可以利用过期机制，设定当前请求计数的key过期时间为1s，但是incr没有提供原子操作的incr过期时间，该如何实现呢？

``` java
local key =KEYS[1]

local expire_time =ARGV[1]

local count =redis.call("INCR", key, 1)

if count == 1 then

    redis.call("EXPIRE", key, expire_time)

end

return count
```

其中KEYS[1]为计数的appKey、ARGV[1]为一个计时时间间隔，单位为s。 最后利用redis的eval命令执行lua脚本，实现incr与expire的原子操作：

``` java
Long current = (Long) jedis.eval(INCR_LUA_SCRIPT, Arrays.asList(key)), Arrays.asList( “1”));

if (current > 500) return false;

return true
```





## Volatitle 关键字 （并发编程相关）

一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：

1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。

2）禁止进行指令重排序。

### 作用:

用volatile修饰之后就变得不一样了：

第一：使用volatile关键字会强制将修改的值立即写入主存；

第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）

第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。

### 关于原子性:

volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。

### 关于有序性:

volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。

使用volatile必须具备以下2个条件：
 1）对变量的写操作不依赖于当前值
 2）该变量没有包含在具有其他变量的不变式中

有序性是指对于单线程的执行代码，执行是按顺序依次进行的。但在多线程环境中，则可能出现乱序现象，因为在编译过程会出现“指令重排”，重排后的指令与原指令的顺序未必一致。因此，前半句指的是线程内保证串行语义执行，后半句则指指“令重排现”象和“工作内存与主内存同步延迟”现象。

### 指令重排序

重排序分为编译重排序和运行重排序两种。下面主要记录编译重排序！

**编译期重排：** 编译源代码时，编译器依据对上下文的分析，对指令进行重排序，以之更适合于CPU的并行执行。

**运行期重排：** CPU在执行过程中，动态分析依赖部件的效能，对指令做重排序优化



#### 什么是指令重排序

JVM为了尽可能的使CPU得到最大的利用率，Java虚拟机在不影响单线程程序执行结果的前提下，尽可能的提高并行度，所以JVM会按照自己的一些规则将程序编写的顺序打乱，比如：写在后面的代码在时间顺序上可能先执行，写在前面的代码在时间顺序上可能会后执行。

举例说明：

```
double r = 2.1; //(1) 
double pi = 3.14;//(2) 
double area = pi*r*r;//(3)

```

在我们程序中编写了如下代码，代码中定义的执行顺序为(1)—>(2)—>(3)，在单线程环境中顺序(1)—>(2)—>(3)和顺序(2)—>(1)—>(3)对执行结果并无影响。(1)和（2）中并不存在着 **数据依赖关系。**所以JVM可能会对(1)、（2）两步打乱顺序执行来优化程序效率。

所以，编译时指令重排序可以理解为JVM为了提高程序效率而可能会将不存在数据依赖关系的代码进行执行顺序的调整的过程。

#### 什么情况可能会造成指令重排序呢

1、一个不是原子的操作，可能会给JVM留下重排序的可能。

2、不存在数据依赖关系的代码语句可能会给JVM留下重排序的可能。

#### 指令重排序带来的影响

指令重排序在单个线程中不会引发问题，但是到了多线程中由于指令重排序的原因可能就会引发一系列的异常。 在Java内存模型（JMM）中有这么一句话很好的描述了重排序的影响：如果在本线程内观察，所有操作都是有序的，如果在一个线程中观察另一个线程，所有操作都是无序的。



### volatile底层实现

volatile是如何来保证可见性的呢？让我们在X86处理器下通过工具获取JIT编译器生成的汇编指令来查看对volatile进行写操作时，CPU会做什么事情呢？

当有volatile变量修饰时会出现汇编指令lock addl $0×0,(%esp),Lock前缀的指令在多核处理器下会引发了两件事情

1）将当前处理器缓存行的数据写回到系统内存。
2）这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。

为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2或其他）后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。

### volatile的优缺点

优点： volatile是轻量级同步机制。在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，是一种比synchronized关键字更轻量级的同步机制。
缺点：volatile只能保证变量的可见性，无法保证原子性。除此之外，由于volatile屏蔽掉了VM中必要的代码优化，所以在效率上会稍微低点。这是两个缺点。volatile禁止了JVM底层的指令重排序优化，造成了一定的性能损耗，但是在多线程环境中提高了安全性。

### 案例:

```java
public class SingleTon {

	private static SingleTon singleTon;

	private SingleTon() {}

	public SingleTon getInstance() {

		if (singleTon == null) {
			synchronized (SingleTon.class) {
				if (singleTon == null) {
					//非原子操作
					singleTon = new SingleTon();
				}
			}
		}
		return singleTon;
	}
}

```

上面是一个双重检查的单例模式，由于使用了双重检查保证了整个上下文环境中只有一个 SingleTon对象，但是在多线程环境中，由于 singleTon = new SingleTon();不是一个原子操作，所以经过JVM的指令重排序以后仍然会引发问题。

singleTon = new SingleTon();语句分为三步：

(1)、在堆内存开辟一块空间

(2)、SingleTon对象初始化

(3)、栈中的 singleTon指向刚刚分配的内存地址

在上面三步中（2）依赖于（1），但是（3）不依赖于（2），所以JVM就可以将这三个步骤进行重排序。假如经过JVM一番重排序后，上面的顺序变成了（1）—>（3）—>（2）。此时有两个线程，线程A和线程B需要获取该单例对象， A线程抢到锁执行同步块中的语句，A线程正在执行（1）—>（3）—>（2）中的（3），此时B线程开始执行了，B线程在锁外面开始做第一次判断 if (singleTon == null)，判断结果为false，然后直接返回singleTon进行使用，但是这时候singleTon还没有初始化，导致出错。

解决办法：
如果使用volatile关键字修饰singleTon变量，禁止JVM进行重排序，使得singleTon在读、写操作前后都会插入内存屏障，避免重排序。

总结:

1.当使用了volatile关键字修饰共享变量以后。每一个线程对共享变量做的更改操作都会被重新刷写到主存中，并且当主存中共享变量的值改变以后，其他线程中的共享变量副本就失效了，需重新从主存中读取值。
2.用volatile关键字的变量的值只要一经改变就会自动刷写到主存中，而不会等待改变该值的线程执行完毕再刷写。
3.当要访问的变量已在synchronized代码块中，或者为常量时，没必要使用volatile；



### 不保证原子性的例子



```
public class Test {
    public static volatile int data = 0;
public static void main(String[] args) throws InterruptedException {
    Thread thread1 = new Thread(() -> {
        for (int i = 0; i < 10; i++) {
            Test.data++;
            System.out.println(data);
        }
    });
    Thread thread2 = new Thread(() -> {
        for (int i = 0; i < 10; i++) {
            Test.data++;
            System.out.println(data);
        }
    });
    thread1.start();
    thread2.start();
    thread1.join();
    thread2.join();
    System.out.println("最终的data为：" + Test.data);
}
}
...
最终的data为：20
```

多线程同时工作去修改一个被volatile关键字修饰的共享变量的时候，比如两个线程对同一个变量volatile int i;进行i++操作，可能会导致运行结果跟预期不一致。这是因为volatile只能保证可见性和有序性，而不能保证原子性。

### 为什么不能保证原子性

首先看一下上面这张图，分析是这样子的：

![Java内存模型](20200715115622174-1669457548712.png)

1、每个线程都有自己的一块工作内存，将主存里的数据缓存到自己的工作内存中。
此时，Threa1跟Thread2都通过read+load将 data = 0 缓存到自己的工作内存中去了。
2、cpu切换到Thread1时，Thread1就会将data = 0 use 进cpu里面计算data++的操作，但是没来得及将计算结果data = 1, assign回Thread1的工作内存中。cpu此时切换到了Thread2，然后在Thread2线程也做了同样的操作（将data = 0 use进cpu并执行data++），继续assign回Thread2的工作内存，并store+write将data = 1写回主存。
因为data是用volatile修饰的，根据缓存一致性协议，其他的线程（这里指的是Thread1）就会立即知道自己工作内存中的数据（data = 0）已经失效了。然而，并没有用！因为Thread1之前已经将data = 0 use 进cpu进行计算去了，cpu切换回Thread1时，Thread1将之前计算好的data = 1 assign 到自己的工作内存中，并store+write写回主存。通过以上的执行顺序，两个线程分别对data做了一次data++操作之后，得到的data = 1 而不是我们预期中的data = 2。
3、总结：多线程同时修改一个被volatile修饰的共享变量时，不能保证原子性，只能保证可见性和顺序性。

### 如何保证原子性

就是用synchronized…只有加了锁，让别的线程连读的机会都没有，才能够安安心心的搞完 read-load-use-assign-store-write全套而不被中途打扰。

```java
public class Test {
    public static volatile int data = 0;
public static void main(String[] args) throws InterruptedException {
    Thread thread1 = new Thread(() -> {
        for (int i = 0; i < 10; i++) {
            synchronized (Test.class) {
                Test.data++;
                System.out.println(data);
            }
        }
    });
    Thread thread2 = new Thread(() -> {
        for (int i = 0; i < 10; i++) {
            synchronized (Test.class) {
                Test.data++;
                System.out.println(data);
            }
        }
    });
    thread1.start();
    thread2.start();
    thread1.join();
    thread2.join();
    System.out.println("最终的data为：" + Test.data);
}
}
```

原子类的原子性是通过 volatile +cas 实现的

## SpringBoot并发编程

### SpringBoot集成一款轻量级高并发服务器——Undertow

Undertow 是红帽公司开发的一款基于 NIO 的高性能 Web嵌入式服务器，它是一个轻量级web服务器，不像我们经常使用的tomcat，它由两个核心 Jar 包组成，加载一个 Web 应用可以小于 10MB 内存。它提供了对Servlet3.1 以及 Web Socket 的支持，undertow底层就是基于netty开发的web服务器

在开始集成之前我先把jetty、tomcat以及undertow的压力测试的数据放在下面，给大家一个直观的感受。

![undertow](20211131903.png)

从中可以看出在**高负载**下Undertow的吞吐量高于Jetty而且随着**压力增大**Jetty和Undertow成功率差距会拉大。而在负载**不是太大**情况下服务器处理能力差不多，jetty还略微高于Undertow。而tomcat的负载能力似乎和Undertow很接近。

　　对比三个服务器发现在Undertow在负载过重情况下比Jetty和Tocmat更加顽强，实践证明在负载继续加大情况下Undertow的成功率高于其它两者，但是在并发不是太大情况下三款服务器整体来看差别不大。

### 快速开始

说了这么多，到底怎么集成undertow？和tomcat一样，SpringBoot是天然集成undertow的，我们只需要把默认的tomcat排除掉，然后引入underundertow的依赖就可以了。

![undertow](20240711132440.png)

**application.yml配置 :**

与原来使用Tomcat时配置无太大差别 , 将tomcat字段改为undertow即可

```
# Undertow 日志存放目录
server.undertow.accesslog.dir=
# 是否启动日志
server.undertow.accesslog.enabled=false 
# 日志格式
server.undertow.accesslog.pattern=common
# 日志文件名前缀
server.undertow.accesslog.prefix=access_log
# 日志文件名后缀
server.undertow.accesslog.suffix=log
# HTTP POST请求最大的大小
server.undertow.max-http-post-size=0 
# 设置IO线程数, 它主要执行非阻塞的任务,它们会负责多个连接, 默认设置每个CPU核心一个线程
server.undertow.io-threads=4
# 阻塞任务线程池, 当执行类似servlet请求阻塞操作, undertow会从这个线程池中取得线程,它的值设置取决于系统的负载
server.undertow.worker-threads=20
# 以下的配置会影响buffer,这些buffer会用于服务器连接的IO操作,有点类似netty的池化内存管理
# 每块buffer的空间大小,越小的空间被利用越充分
server.undertow.buffer-size=1024
# 每个区分配的buffer数量 , 所以pool的大小是buffer-size * buffers-per-region
server.undertow.buffers-per-region=1024
# 是否分配的直接内存
server.undertow.direct-buffers=true
```

综上，当我们系统负载比较高的时候我们可以考虑切换成undertow服务器，或者我们的微服务系统需要一个轻量级的容器的话我们也可以选择undertow。

## 参考文献：

作者：garychenqin 

链接：https://www.jianshu.com/p/08aa952e8bc2



